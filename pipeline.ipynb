{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 2.2.2+cu121 with CUDA 1201 (you have 2.2.2+cu118)\n",
      "    Python  3.10.11 (you have 3.10.9)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n",
      "A matching Triton is not available, some optimizations will not be enabled\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xformers\\__init__.py\", line 55, in _is_triton_available\n",
      "    from xformers.triton.softmax import softmax as triton_softmax  # noqa\n",
      "  File \"c:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xformers\\triton\\softmax.py\", line 11, in <module>\n",
      "    import triton\n",
      "ModuleNotFoundError: No module named 'triton'\n",
      "c:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\diffusers\\utils\\outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "399b9e17033d4585bb621afd49f3579f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\diffusers\\utils\\outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
    "pipe = pipe.to(\"cuda\")\n",
    "pipe.safety_checker = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this function to generate images and save them to a folder\n",
    "\n",
    "def gen_images(prompt, folder_name):\n",
    "    for i in range(100):\n",
    "        image = pipe(prompt).images[0]\n",
    "        image.save(f\"{folder_name}/image_{i+1}.png\")\n",
    "    print(\"Done generating images\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "clip_model = clip_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clip_embeddings(images):\n",
    "  \"\"\"\n",
    "    This function takes a list of images as input,\n",
    "    returning a list of clip embeddings of the images.\n",
    "\n",
    "    :param images: The input image as a string.\n",
    "    :return: A list of clip embeddings.\n",
    "    \"\"\"\n",
    "  inputs = clip_processor(images=images, return_tensors=\"pt\", padding=True).to(device)\n",
    "\n",
    "  with torch.no_grad():\n",
    "      image_features = clip_model.get_image_features(**inputs)\n",
    "\n",
    "  return image_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_from_folder(folder_name):\n",
    "    embeddings = []\n",
    "    for img in os.listdir(folder_name):\n",
    "        image = Image.open(f\"{folder_name}/{img}\")\n",
    "        image = image.convert(\"RGB\")\n",
    "        embeddings.append(get_clip_embeddings([image]))\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get embedding of dog images folder\n",
    "dog_folder = \"dog images\"\n",
    "dog_embeddings = get_embedding_from_folder(dog_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dog_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# Convert the embeddings to numpy array\n",
    "dog_embeddings = np.array([embedding.cpu().numpy() for embedding in dog_embeddings]).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_clusters = KMeans(n_clusters=10, random_state=0, n_init=\"auto\").fit(dog_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 4, 6, 9, 1, 1, 4, 4, 1, 8, 9, 1, 8, 7, 1, 8, 1, 1, 4, 4, 7, 8,\n",
       "       1, 4, 4, 1, 8, 1, 7, 1, 8, 9, 4, 1, 2, 1, 3, 0, 3, 8, 1, 4, 8, 4,\n",
       "       8, 4, 1, 4, 7, 8, 3, 4, 1, 3, 0, 9, 4, 4, 9, 9, 6, 1, 4, 4, 2, 4,\n",
       "       8, 4, 4, 1, 2, 4, 1, 4, 1, 3, 4, 4, 6, 1, 8, 4, 9, 4, 6, 1, 9, 6,\n",
       "       4, 1, 5, 4, 4, 0, 1, 4, 1, 9, 5, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_clusters.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0940939 ,  0.14876989, -0.11178604, ...,  0.6110529 ,\n",
       "        -0.13133484,  0.2154733 ],\n",
       "       [ 0.09988901,  0.20128758, -0.12159383, ...,  0.6297776 ,\n",
       "         0.0104358 , -0.1066051 ],\n",
       "       [-0.16243565,  0.15555695, -0.07923102, ...,  0.46179855,\n",
       "         0.13123655, -0.33283296],\n",
       "       ...,\n",
       "       [ 0.02061935, -0.03642638, -0.21178746, ...,  0.61320156,\n",
       "         0.01741252,  0.07048526],\n",
       "       [ 0.01687707,  0.15982442, -0.10077201, ...,  0.4878475 ,\n",
       "         0.09455046, -0.05054102],\n",
       "       [-0.01419756,  0.20010601, -0.00342564, ...,  0.66272056,\n",
       "        -0.09371414, -0.02582545]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_clusters.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get different images from each cluster\n",
    "def get_images_from_cluster(cluster_number, folder_name):\n",
    "    cluster_images = []\n",
    "    for i, label in enumerate(kmeans_clusters.labels_):\n",
    "        if label == cluster_number:\n",
    "            cluster_images.append(f\"{folder_name}/image_{i+1}.png\")\n",
    "    return cluster_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get images for all the clusters\n",
    "cluster_images = []\n",
    "for i in range(10):\n",
    "    cluster_images.append(get_images_from_cluster(i, dog_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['dog images/image_38.png',\n",
       "  'dog images/image_55.png',\n",
       "  'dog images/image_94.png'],\n",
       " ['dog images/image_5.png',\n",
       "  'dog images/image_6.png',\n",
       "  'dog images/image_9.png',\n",
       "  'dog images/image_12.png',\n",
       "  'dog images/image_15.png',\n",
       "  'dog images/image_17.png',\n",
       "  'dog images/image_18.png',\n",
       "  'dog images/image_23.png',\n",
       "  'dog images/image_26.png',\n",
       "  'dog images/image_28.png',\n",
       "  'dog images/image_30.png',\n",
       "  'dog images/image_34.png',\n",
       "  'dog images/image_36.png',\n",
       "  'dog images/image_41.png',\n",
       "  'dog images/image_47.png',\n",
       "  'dog images/image_53.png',\n",
       "  'dog images/image_62.png',\n",
       "  'dog images/image_70.png',\n",
       "  'dog images/image_73.png',\n",
       "  'dog images/image_75.png',\n",
       "  'dog images/image_80.png',\n",
       "  'dog images/image_86.png',\n",
       "  'dog images/image_90.png',\n",
       "  'dog images/image_95.png',\n",
       "  'dog images/image_97.png'],\n",
       " ['dog images/image_35.png',\n",
       "  'dog images/image_65.png',\n",
       "  'dog images/image_71.png'],\n",
       " ['dog images/image_37.png',\n",
       "  'dog images/image_39.png',\n",
       "  'dog images/image_51.png',\n",
       "  'dog images/image_54.png',\n",
       "  'dog images/image_76.png',\n",
       "  'dog images/image_100.png'],\n",
       " ['dog images/image_2.png',\n",
       "  'dog images/image_7.png',\n",
       "  'dog images/image_8.png',\n",
       "  'dog images/image_19.png',\n",
       "  'dog images/image_20.png',\n",
       "  'dog images/image_24.png',\n",
       "  'dog images/image_25.png',\n",
       "  'dog images/image_33.png',\n",
       "  'dog images/image_42.png',\n",
       "  'dog images/image_44.png',\n",
       "  'dog images/image_46.png',\n",
       "  'dog images/image_48.png',\n",
       "  'dog images/image_52.png',\n",
       "  'dog images/image_57.png',\n",
       "  'dog images/image_58.png',\n",
       "  'dog images/image_63.png',\n",
       "  'dog images/image_64.png',\n",
       "  'dog images/image_66.png',\n",
       "  'dog images/image_68.png',\n",
       "  'dog images/image_69.png',\n",
       "  'dog images/image_72.png',\n",
       "  'dog images/image_74.png',\n",
       "  'dog images/image_77.png',\n",
       "  'dog images/image_78.png',\n",
       "  'dog images/image_82.png',\n",
       "  'dog images/image_84.png',\n",
       "  'dog images/image_89.png',\n",
       "  'dog images/image_92.png',\n",
       "  'dog images/image_93.png',\n",
       "  'dog images/image_96.png'],\n",
       " ['dog images/image_91.png', 'dog images/image_99.png'],\n",
       " ['dog images/image_1.png',\n",
       "  'dog images/image_3.png',\n",
       "  'dog images/image_61.png',\n",
       "  'dog images/image_79.png',\n",
       "  'dog images/image_85.png',\n",
       "  'dog images/image_88.png'],\n",
       " ['dog images/image_14.png',\n",
       "  'dog images/image_21.png',\n",
       "  'dog images/image_29.png',\n",
       "  'dog images/image_49.png'],\n",
       " ['dog images/image_10.png',\n",
       "  'dog images/image_13.png',\n",
       "  'dog images/image_16.png',\n",
       "  'dog images/image_22.png',\n",
       "  'dog images/image_27.png',\n",
       "  'dog images/image_31.png',\n",
       "  'dog images/image_40.png',\n",
       "  'dog images/image_43.png',\n",
       "  'dog images/image_45.png',\n",
       "  'dog images/image_50.png',\n",
       "  'dog images/image_67.png',\n",
       "  'dog images/image_81.png'],\n",
       " ['dog images/image_4.png',\n",
       "  'dog images/image_11.png',\n",
       "  'dog images/image_32.png',\n",
       "  'dog images/image_56.png',\n",
       "  'dog images/image_59.png',\n",
       "  'dog images/image_60.png',\n",
       "  'dog images/image_83.png',\n",
       "  'dog images/image_87.png',\n",
       "  'dog images/image_98.png']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
